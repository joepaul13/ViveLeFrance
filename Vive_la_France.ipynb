{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNm5TCBGbN7R0PIZzk2UZS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joepaul13/ViveLeFrance/blob/main/Vive_la_France.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YFHZRUCzVTvQ"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "  \n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "fJQwk0B6WbYW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodetoAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodetoAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  return s"
      ],
      "metadata": {
        "id": "iYJRSVytX312"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse = False):\n",
        "  print(\"Reading Lines...\")\n",
        "  lines = open('/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "  if reverse:\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    input_lang = Lang(lang2)\n",
        "    output_lang = Lang(lang1)\n",
        "\n",
        "  else:\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "  return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "wb3snRncY5tG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am\", \"i m\",\n",
        "    \"he is\", \"he s\",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re\",\n",
        "    \"we are\", \"we re\",\n",
        "    \"they are\", \"they re\"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "    len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "    p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "mdWZEho_m68t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  print(\"Read %s sentence pairs\" % len(pairs))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print(\"Counted Words:\")\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "id": "cdcC2wZon0YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b28919b-80bf-4f28-f368-0f4ee0df859b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11893 sentence pairs\n",
            "Counting words...\n",
            "Counted Words:\n",
            "fra 4920\n",
            "eng 3228\n",
            "['je suis concerne par sa sante .', 'i am concerned about his health .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "0wXmJigoXBLl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "Rl5ao3deYo3K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout_p = dropout_p\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "    attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "    output = torch.cat((embedded[0], hidden[0]), 1)\n",
        "    output = self.attn_combine(output).unsqueeze(0)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = F.log_softmax(self.out(output[0]), dim = 1)\n",
        "    return output, hidden, attn_weights\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "metadata": {
        "id": "jbDVOObvY5Iy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype = torch.long, device = device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "GsiQT09dg2wa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length = MAX_LENGTH):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
        "\n",
        "  loss = 0\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[SOS_token]], device = device)\n",
        "  decoder_hidden = encoder_hidden\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]\n",
        "\n",
        "  else:\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  return loss.item() / target_length\n"
      ],
      "metadata": {
        "id": "Id8lAcWpjHUm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s/60)\n",
        "  s -= m*60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (-%s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "tQtNqFdzJowr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  loc = ticker.MultipleLocator(base = 0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ],
      "metadata": {
        "id": "XRlvU742QaFM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every = 1000, plot_every = 100, learning_rate = 0.01):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0\n",
        "  plot_loss_total = 0\n",
        "\n",
        "  encoder_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
        "  decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
        "  training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for iter in range(1, n_iters+1):\n",
        "    training_pair = training_pairs[iter-1]\n",
        "    input_tensor = training_pair[0]\n",
        "    target_tensor = training_pair[1]\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if iter % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters*100, print_loss_avg))\n",
        "\n",
        "    if iter % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_avg = 0\n",
        "\n",
        "  showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "YZezt0dPMp6W"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "    "
      ],
      "metadata": {
        "id": "qEyJ5DhlRCd-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "A-mUUMLel1Vi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE1IVePRl4An",
        "outputId": "8c8b50b1-d2ff-48e4-fbb3-e460a5275710"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 53s (-54m 25s) (5000 6%) 3.0618\n",
            "7m 57s (-51m 43s) (10000 13%) 2.4898\n",
            "12m 6s (-48m 24s) (15000 20%) 2.1312\n",
            "16m 9s (-44m 25s) (20000 26%) 1.8762\n",
            "20m 11s (-40m 23s) (25000 33%) 1.6711\n",
            "24m 14s (-36m 22s) (30000 40%) 1.4860\n",
            "28m 18s (-32m 20s) (35000 46%) 1.3021\n",
            "32m 21s (-28m 18s) (40000 53%) 1.1891\n",
            "36m 29s (-24m 19s) (45000 60%) 1.0567\n",
            "40m 37s (-20m 18s) (50000 66%) 0.9580\n",
            "44m 37s (-16m 13s) (55000 73%) 0.8666\n",
            "48m 35s (-12m 8s) (60000 80%) 0.7699\n",
            "52m 33s (-8m 5s) (65000 86%) 0.7204\n",
            "56m 33s (-4m 2s) (70000 93%) 0.6530\n",
            "60m 37s (-0m 0s) (75000 100%) 0.6100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.ticker:Locator attempting to generate 5708 ticks ([-47.400000000000006, ..., 1094.0]), which exceeds Locator.MAXTICKS (1000).\n",
            "WARNING:matplotlib.ticker:Locator attempting to generate 5708 ticks ([-47.400000000000006, ..., 1094.0]), which exceeds Locator.MAXTICKS (1000).\n",
            "WARNING:matplotlib.ticker:Locator attempting to generate 5708 ticks ([-47.400000000000006, ..., 1094.0]), which exceeds Locator.MAXTICKS (1000).\n",
            "WARNING:matplotlib.ticker:Locator attempting to generate 5708 ticks ([-47.400000000000006, ..., 1094.0]), which exceeds Locator.MAXTICKS (1000).\n",
            "WARNING:matplotlib.ticker:Locator attempting to generate 5708 ticks ([-47.400000000000006, ..., 1094.0]), which exceeds Locator.MAXTICKS (1000).\n",
            "WARNING:matplotlib.ticker:Locator attempting to generate 5708 ticks ([-47.400000000000006, ..., 1094.0]), which exceeds Locator.MAXTICKS (1000).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeAMRrUfl6m6",
        "outputId": "dc5f2386-d284-44b8-9a5a-6f92d01ee026"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> je suis tout a fait pour .\n",
            "= i m all for that .\n",
            "< i m all for that . <EOS>\n",
            "\n",
            "> je me suis decide a m y rendre .\n",
            "= i made up my mind to go there .\n",
            "< i made up my mind to go there . <EOS>\n",
            "\n",
            "> nous sommes gaves .\n",
            "= we re stuffed .\n",
            "< we re stuffed . <EOS>\n",
            "\n",
            "> je suis presque pret .\n",
            "= i am almost ready .\n",
            "< i m almost ready . <EOS>\n",
            "\n",
            "> ils viennent pour moi .\n",
            "= they re coming for me .\n",
            "< they re coming for me . <EOS>\n",
            "\n",
            "> je ne suis pas aussi occupe que tom .\n",
            "= i m not as busy as tom .\n",
            "< i m not as busy as tom . <EOS>\n",
            "\n",
            "> tu es tres talentueuse .\n",
            "= you re very talented .\n",
            "< you re very talented . <EOS>\n",
            "\n",
            "> je suis heureux que vous aimiez mes amis .\n",
            "= i m glad you liked my friends .\n",
            "< i m glad you liked my friends . <EOS>\n",
            "\n",
            "> ce sont toutes les miennes .\n",
            "= they re all mine .\n",
            "< they re all mine . <EOS>\n",
            "\n",
            "> je ne suis pas une sainte .\n",
            "= i m not a saint .\n",
            "< i m no saint . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_words, attentions = evaluate(encoder1, attn_decoder1, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vc449ZFtxtj",
        "outputId": "8decf745-381a-46b4-86fb-fc8faf97c4a8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc12cebfc70>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm0KH9CIt2r4",
        "outputId": "635cd27d-f468-47f2-a72b-ca9c2bc7fac5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = elle a cinq ans de moins que moi .\n",
            "output = she is five years younger than me . <EOS>\n",
            "input = elle est trop petit .\n",
            "output = she s too fat . <EOS>\n",
            "input = je ne crains pas de mourir .\n",
            "output = i m not scared of death . <EOS>\n",
            "input = c est un jeune directeur plein de talent .\n",
            "output = he s a talented young man . <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-9b51ff8fc28e>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-45-9b51ff8fc28e>:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6I65EnMst5ng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}